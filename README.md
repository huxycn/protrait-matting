# Portrait Matting #
[Deep Automatic Portrait Matting](http://www.cse.cuhk.edu.hk/leojia/projects/automatting/index.html) and
[Automatic Portrait Segmentation for Image Stylization](http://xiaoyongshen.me/webpage_portrait/index.html)
implementation which predicts alpha or binary masks of portrait images automatically.

This is NOT official implementation.

## Notice of License ##
This software is released under the GPL License except `data_original` directory.

Data under `data_original` directory is copied from the paper author's.
Rights of the data belong to them.

We created our original alpha masks and the following results are generated by them.

## Implemented Models ##
* FCN8s for binary segmentation with RGB image
* FCN8s for binary segmentation with RGB image, mean mask and grid images
* FCN8s for trimap segmentation with RGB image, mean mask and grid images
* FCN8s and matting layer with RGB image, mean mask and grid images

## Testing Environments ##
* OS: Ubuntu 16.04 and Latest Arch Linux
* Python: 3.5
* Chainer: 3.4.0
* OpenCV: 3.4.0
* Dlib: 19.9.0

## Training ##
Training data which is contained this repository is binary mask for segmentation created by paper's author.

**For training of trimap and matting, extra alpha masks are needed.**

### Preparation ###
```bash
# Download images from the internet.
$ python scripts/prepare_seg_dataset.py

# Generate mean masks and grids.
$ python scripts/prepare_seg_plus_dataset.py

# Generate trimaps from alpha masks. (extra alpha mask are needed)
$ python scripts/prepare_seg_tri_dataset.py

# Computes loss weight matrixs. (extra alpha mask are needed)
$ python scripts/prepare_matting_dataset.py
```

### Training ###
```bash
$ python scripts/train.py --mode {seg,seg+,seg_tri,mat}
```

### Testing ###
```bash
$ python scripts/train.py --mode {seg,seg+,seg_tri,mat} --model_path <path> -i <image path>
```

## Results ##
### Matting ###
First column is input image. Second column is output alpha mask. Third column is background replacement result.

<img src="https://raw.githubusercontent.com/takiyu/portrait_matting/master/sample_images/color_1.jpg" width="250" /> <img src="https://raw.githubusercontent.com/takiyu/portrait_matting/master/sample_images/alpha_1.jpg" width="250" /> <img src="https://raw.githubusercontent.com/takiyu/portrait_matting/master/sample_images/color_vis_1.jpg" width="250" />

<img src="https://raw.githubusercontent.com/takiyu/portrait_matting/master/sample_images/color_2.jpg" width="250" /> <img src="https://raw.githubusercontent.com/takiyu/portrait_matting/master/sample_images/alpha_2.jpg" width="250" /> <img src="https://raw.githubusercontent.com/takiyu/portrait_matting/master/sample_images/color_vis_2.jpg" width="250" />

<img src="https://raw.githubusercontent.com/takiyu/portrait_matting/master/sample_images/color_3.jpg" width="250" /> <img src="https://raw.githubusercontent.com/takiyu/portrait_matting/master/sample_images/alpha_3.jpg" width="250" /> <img src="https://raw.githubusercontent.com/takiyu/portrait_matting/master/sample_images/color_vis_3.jpg" width="250" />

<img src="https://raw.githubusercontent.com/takiyu/portrait_matting/master/sample_images/color_4.jpg" width="250" /> <img src="https://raw.githubusercontent.com/takiyu/portrait_matting/master/sample_images/alpha_4.jpg" width="250" /> <img src="https://raw.githubusercontent.com/takiyu/portrait_matting/master/sample_images/color_vis_4.jpg" width="250" />

<img src="https://raw.githubusercontent.com/takiyu/portrait_matting/master/sample_images/color_5.jpg" width="250" /> <img src="https://raw.githubusercontent.com/takiyu/portrait_matting/master/sample_images/alpha_5.jpg" width="250" /> <img src="https://raw.githubusercontent.com/takiyu/portrait_matting/master/sample_images/color_vis_5.jpg" width="250" />

## ToDo ##
- [ ] Collect more data.
- [ ] Seek more effective training method about matting layer.
- [ ] Tune hyper parameters automatically.
